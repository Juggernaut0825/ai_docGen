#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»ç¨‹åºï¼šAIæ–‡æ¡£ç”Ÿæˆå™¨ - å¢å¼ºç‰ˆ
æ”¯æŒä½ç½®æ„ŸçŸ¥çš„AIå­—æ®µæ˜ å°„å’Œæ™ºèƒ½æ¨¡æ¿å¡«å……
"""

import os
import json
import logging
import subprocess
from datetime import datetime
from typing import Dict, Any, List
from docx import Document
from openai import OpenAI

# å¯¼å…¥æ–°çš„æç¤ºè¯å·¥å…·
from prompt_utils import PromptTemplates, PromptHelper

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class EnhancedAIDocGenerator:
    """å¢å¼ºç‰ˆAIæ–‡æ¡£ç”Ÿæˆå™¨ - æ”¯æŒä½ç½®æ„ŸçŸ¥æ˜ å°„"""
    
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–OpenRouterå®¢æˆ·ç«¯"""
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key,
        )
        self.model = "google/gemini-2.5-pro-preview"
        self.prompt_templates = PromptTemplates()
        self.prompt_helper = PromptHelper()
        logger.info("ğŸ¤– å¢å¼ºç‰ˆAIç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def convert_doc_to_docx(self, doc_path: str) -> str:
        """
        ä½¿ç”¨LibreOfficeå°†.docæ–‡ä»¶è½¬æ¢ä¸º.docxæ–‡ä»¶
        
        Args:
            doc_path: .docæ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬æ¢åçš„.docxæ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸ”„ å¼€å§‹DOCåˆ°DOCXè½¬æ¢...")
        
        if not os.path.exists(doc_path):
            logger.error(f"âŒ DOCæ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
            raise FileNotFoundError(f"DOCæ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        docx_path = doc_path.replace('.doc', '_converted.docx')
        
        try:
            # æ£€æŸ¥LibreOfficeæ˜¯å¦å¯ç”¨
            logger.info("ğŸ” æ£€æŸ¥LibreOfficeå¯ç”¨æ€§...")
            
            # å°è¯•å¤šä¸ªå¯èƒ½çš„LibreOfficeè·¯å¾„
            libreoffice_paths = [
                '/Applications/LibreOffice.app/Contents/MacOS/soffice',  # macOS
                'libreoffice',  # Linux/Windows PATH
                'soffice',  # å¤‡ç”¨å‘½ä»¤
            ]
            
            libreoffice_cmd = None
            for path in libreoffice_paths:
                try:
                    result = subprocess.run([path, '--version'], 
                                          capture_output=True, 
                                          text=True, 
                                          timeout=10)
                    if result.returncode == 0:
                        libreoffice_cmd = path
                        logger.info(f"âœ… æ‰¾åˆ°LibreOffice: {path}")
                        break
                except (FileNotFoundError, subprocess.TimeoutExpired):
                    continue
            
            if not libreoffice_cmd:
                logger.error("âŒ æœªæ‰¾åˆ°LibreOfficeï¼Œè¯·ç¡®ä¿å·²å®‰è£…LibreOffice")
                raise RuntimeError("LibreOfficeæœªå®‰è£…æˆ–ä¸å¯ç”¨")
            
            # æ‰§è¡Œè½¬æ¢
            logger.info(f"ğŸ“„ æ­£åœ¨è½¬æ¢: {doc_path} -> {docx_path}")
            
            # åˆ é™¤å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
            if os.path.exists(docx_path):
                os.remove(docx_path)
                logger.info("ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„è½¬æ¢æ–‡ä»¶")
            
            # LibreOfficeè½¬æ¢å‘½ä»¤
            cmd = [
                libreoffice_cmd,
                '--headless',
                '--convert-to', 'docx',
                '--outdir', os.path.dirname(doc_path),
                doc_path
            ]
            
            logger.info(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=30)
            
            if result.returncode != 0:
                logger.error(f"âŒ LibreOfficeè½¬æ¢å¤±è´¥: {result.stderr}")
                raise RuntimeError(f"LibreOfficeè½¬æ¢å¤±è´¥: {result.stderr}")
            
            # æ£€æŸ¥è½¬æ¢åçš„æ–‡ä»¶
            expected_docx = doc_path.replace('.doc', '.docx')
            if os.path.exists(expected_docx):
                # é‡å‘½åä¸ºæˆ‘ä»¬æœŸæœ›çš„æ–‡ä»¶å
                if expected_docx != docx_path:
                    os.rename(expected_docx, docx_path)
                
                logger.info(f"âœ… è½¬æ¢æˆåŠŸ: {docx_path}")
                return docx_path
            else:
                logger.error(f"âŒ è½¬æ¢åçš„æ–‡ä»¶æœªæ‰¾åˆ°: {expected_docx}")
                raise RuntimeError("è½¬æ¢åçš„æ–‡ä»¶æœªæ‰¾åˆ°")
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ LibreOfficeè½¬æ¢è¶…æ—¶")
            raise RuntimeError("LibreOfficeè½¬æ¢è¶…æ—¶")
        except Exception as e:
            logger.error(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise
    
    def stage1_analyze_template_with_position(self, template_path: str) -> Dict[str, str]:
        """
        é˜¶æ®µ1ï¼šå¢å¼ºç‰ˆæ¨¡æ¿åˆ†æ - æå–ä½ç½®ä¿¡æ¯å’Œä¸Šä¸‹æ–‡
        """
        logger.info("ğŸ” é˜¶æ®µ1ï¼šå¼€å§‹ä½ç½®æ„ŸçŸ¥çš„æ¨¡æ¿ç»“æ„åˆ†æ...")
        
        try:
            # è¯»å–Wordæ–‡æ¡£å†…å®¹
            doc = Document(template_path)
            template_content = ""
            
            logger.info(f"ğŸ“„ æ­£åœ¨è¯»å–æ¨¡æ¿æ–‡ä»¶: {template_path}")
            
            # å¢å¼ºç‰ˆæ¨¡æ¿å†…å®¹æå– - åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯
            table_count = 0
            for table in doc.tables:
                table_count += 1
                logger.info(f"ğŸ“‹ å¤„ç†ç¬¬ {table_count} ä¸ªè¡¨æ ¼")
                template_content += f"\n=== è¡¨æ ¼ {table_count} ===\n"
                
                for row_idx, row in enumerate(table.rows):
                    row_content = ""
                    for cell_idx, cell in enumerate(row.cells):
                        cell_text = cell.text.strip()
                        if cell_text:
                            row_content += f"[Row{row_idx+1}Col{cell_idx+1}]: {cell_text} | "
                    
                    if row_content:
                        template_content += f"ç¬¬{row_idx+1}è¡Œ: {row_content}\n"
                        
                        # æ·»åŠ ä¸Šä¸‹æ–‡åˆ†æ
                        if row_idx > 0:
                            prev_row_content = ""
                            for cell_idx, cell in enumerate(table.rows[row_idx-1].cells):
                                prev_cell_text = cell.text.strip()
                                if prev_cell_text:
                                    prev_row_content += f"{prev_cell_text} | "
                            if prev_row_content:
                                template_content += f"  ä¸Šæ–¹è¡Œå†…å®¹: {prev_row_content}\n"
            
            logger.info(f"ğŸ“Š å¢å¼ºç‰ˆæ¨¡æ¿å†…å®¹æå–å®Œæˆï¼Œå…± {table_count} ä¸ªè¡¨æ ¼")
            
            # ä½¿ç”¨å¢å¼ºç‰ˆæç¤ºè¯åˆ†ææ¨¡æ¿ç»“æ„
            prompt = self.prompt_templates.get_template_analysis_prompt(template_content)
            
            logger.info("ğŸ§  æ­£åœ¨è°ƒç”¨AIè¿›è¡Œä½ç½®æ„ŸçŸ¥çš„æ¨¡æ¿å­—æ®µåˆ†æ...")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                extra_headers={
                    "HTTP-Referer": "ai-doc-generator",
                    "X-Title": "AI Document Generator Enhanced",
                }
            )
            
            # è§£æè¿”å›çš„JSON
            json_text = self.prompt_helper.extract_json_from_response(response.choices[0].message.content)
            
            # éªŒè¯JSONæœ‰æ•ˆæ€§
            if not self.prompt_helper.validate_json_structure(json_text):
                logger.warning("âš ï¸ AIè¿”å›çš„JSONæ ¼å¼æ— æ•ˆï¼Œä½¿ç”¨é™çº§ç»“æ„")
                template_structure = self.prompt_helper.create_fallback_structure(template_content)
            else:
                template_structure = json.loads(json_text)
            
            logger.info(f"âœ… æˆåŠŸæå– {len(template_structure)} ä¸ªä½ç½®æ„ŸçŸ¥å­—æ®µ:")
            for key, value in template_structure.items():
                logger.info(f"   ğŸ“Œ {key}: {value}")
            
            # è®°å½•å­—æ®µç»Ÿè®¡ä¿¡æ¯
            self._log_field_statistics(template_structure)
            
            return template_structure
            
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ1é”™è¯¯: {e}")
            # è¿”å›é™çº§ç»“æ„
            fallback_structure = self.prompt_helper.create_fallback_structure("")
            logger.warning("âš ï¸ ä½¿ç”¨é™çº§æ¨¡æ¿ç»“æ„")
            return fallback_structure
    
    def stage2_load_json_data(self, json_file_path: str) -> Dict[str, str]:
        """
        é˜¶æ®µ2ï¼šä»JSONæ–‡ä»¶åŠ è½½æ•°æ®ï¼ˆå¢å¼ºç‰ˆæ—¥å¿—ï¼‰
        """
        logger.info("ğŸ“‚ é˜¶æ®µ2ï¼šå¼€å§‹åŠ è½½JSONæ•°æ®...")
        
        try:
            if not os.path.exists(json_file_path):
                logger.error(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
                return {}
            
            logger.info(f"ğŸ“„ æ­£åœ¨è¯»å–JSONæ–‡ä»¶: {json_file_path}")
            
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ªæ•°æ®å­—æ®µ:")
            for key, value in data.items():
                preview = value[:50] + "..." if len(str(value)) > 50 else str(value)
                logger.info(f"   ğŸ“Œ {key}: {preview}")
            
            # è®°å½•æ•°æ®å­—æ®µç»Ÿè®¡
            self._log_data_statistics(data)
            
            return data
            
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ2é”™è¯¯: {e}")
            return {}
    
    def stage2_5_enhanced_ai_field_mapping(self, template_structure: Dict[str, str], input_data: Dict[str, str]) -> Dict[str, str]:
        """
        é˜¶æ®µ2.5ï¼šå¢å¼ºç‰ˆAIæ™ºèƒ½å­—æ®µæ˜ å°„
        
        Args:
            template_structure: ä½ç½®æ„ŸçŸ¥çš„æ¨¡æ¿å­—æ®µç»“æ„
            input_data: è¾“å…¥æ•°æ®
            
        Returns:
            æ˜ å°„åçš„æ•°æ®ï¼Œä½¿ç”¨ä½ç½®æ„ŸçŸ¥çš„æ¨¡æ¿å­—æ®µåä½œä¸ºé”®
        """
        logger.info("ğŸ§  é˜¶æ®µ2.5ï¼šå¼€å§‹å¢å¼ºç‰ˆAIå­—æ®µæ˜ å°„...")
        
        try:
            # æ„å»ºå¢å¼ºç‰ˆAIæ˜ å°„æç¤º
            base_prompt = self.prompt_templates.get_field_mapping_prompt(template_structure, input_data)
            enhanced_prompt = self.prompt_templates.enhance_mapping_prompt_with_examples(base_prompt)
            
            logger.info("ğŸ§  æ­£åœ¨è°ƒç”¨AIè¿›è¡Œå¢å¼ºç‰ˆå­—æ®µæ˜ å°„...")
            logger.info(f"ğŸ“Š æ¨¡æ¿å­—æ®µæ•°é‡: {len(template_structure)}")
            logger.info(f"ğŸ“Š è¾“å…¥æ•°æ®å­—æ®µæ•°é‡: {len(input_data)}")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": enhanced_prompt}],
                extra_headers={
                    "HTTP-Referer": "ai-doc-generator",
                    "X-Title": "AI Document Generator Enhanced",
                }
            )
            
            # è§£æè¿”å›çš„JSON
            json_text = self.prompt_helper.extract_json_from_response(response.choices[0].message.content)
            
            # éªŒè¯JSONæœ‰æ•ˆæ€§
            if not self.prompt_helper.validate_json_structure(json_text):
                logger.warning("âš ï¸ AIæ˜ å°„è¿”å›çš„JSONæ ¼å¼æ— æ•ˆï¼Œå°è¯•ç›´æ¥æ˜ å°„")
                mapped_data = self._fallback_field_mapping(template_structure, input_data)
            else:
                mapped_data = json.loads(json_text)
            
            logger.info(f"âœ… æˆåŠŸæ˜ å°„ {len(mapped_data)} ä¸ªå­—æ®µ:")
            for key, value in mapped_data.items():
                preview = value[:50] + "..." if len(str(value)) > 50 else str(value)
                logger.info(f"   ğŸ”— {key}: {preview}")
            
            # è¯¦ç»†çš„æ˜ å°„ç»Ÿè®¡å’ŒéªŒè¯
            self._log_mapping_statistics(template_structure, input_data, mapped_data)
            
            return mapped_data
            
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ2.5é”™è¯¯: {e}")
            logger.warning("âš ï¸ AIå­—æ®µæ˜ å°„å¤±è´¥ï¼Œä½¿ç”¨é™çº§æ˜ å°„ç­–ç•¥")
            return self._fallback_field_mapping(template_structure, input_data)
    
    def stage3_position_aware_template_filling(self, template_path: str, output_path: str, mapped_data: Dict[str, str], template_structure: Dict[str, str]):
        """
        é˜¶æ®µ3ï¼šä½ç½®æ„ŸçŸ¥çš„æ™ºèƒ½æ¨¡æ¿å¡«å……
        
        Args:
            template_path: æ¨¡æ¿æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            mapped_data: ä½ç½®æ„ŸçŸ¥æ˜ å°„åçš„æ•°æ®
            template_structure: æ¨¡æ¿ç»“æ„ï¼ˆç”¨äºéªŒè¯ï¼‰
        """
        logger.info("ğŸ“ é˜¶æ®µ3ï¼šå¼€å§‹ä½ç½®æ„ŸçŸ¥çš„æ™ºèƒ½æ¨¡æ¿å¡«å……...")
        
        if not os.path.exists(template_path):
            logger.error(f"âŒ æ¨¡æ¿æ–‡ä»¶æœªæ‰¾åˆ°: {template_path}")
            return False

        try:
            logger.info(f"ğŸ“„ æ­£åœ¨æ‰“å¼€æ¨¡æ¿: {template_path}")
            doc = Document(template_path)

            if not doc.tables:
                logger.error("âŒ æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼")
                return False

            table = doc.tables[0]
            filled_fields = []
            skipped_fields = []
            position_matches = {}

            logger.info("ğŸ” å¼€å§‹ä½ç½®æ„ŸçŸ¥çš„æ™ºèƒ½æœç´¢å’Œå¡«å……...")

            # æ„å»ºä½ç½®æ˜ å°„è¡¨
            for key in mapped_data.keys():
                if mapped_data[key]:  # åªå¤„ç†æœ‰å€¼çš„å­—æ®µ
                    position_info = self._parse_position_key(key)
                    if position_info:
                        position_matches[key] = position_info
                        logger.info(f"ğŸ¯ ä½ç½®è§£æ: {key} -> Row{position_info['row']}, Col{position_info['col']}, Context: {position_info.get('context', 'N/A')}")

            # éå†è¡¨æ ¼è¿›è¡Œä½ç½®åŒ¹é…å¡«å……
            for row_idx, row in enumerate(table.rows):
                for cell_idx, cell in enumerate(row.cells):
                    cell_text = cell.text.strip()
                    
                    # æŸ¥æ‰¾åŒ¹é…çš„ä½ç½®å­—æ®µ
                    for field_key, field_value in mapped_data.items():
                        if not field_value:  # è·³è¿‡ç©ºå€¼
                            continue
                            
                        position_info = position_matches.get(field_key)
                        if not position_info:
                            continue
                        
                        # ä½ç½®åŒ¹é…é€»è¾‘
                        if self._is_position_match(row_idx, cell_idx, cell_text, position_info, row):
                            try:
                                success = self._fill_cell_by_position(cell, row, cell_idx, field_value, position_info)
                                if success:
                                    filled_fields.append(f"{field_key} -> {field_value[:50]}{'...' if len(field_value) > 50 else ''}")
                                    logger.info(f"   âœï¸ ä½ç½®å¡«å……æˆåŠŸ: {field_key}")
                                else:
                                    skipped_fields.append(f"{field_key}: å¡«å……å¤±è´¥")
                                    logger.warning(f"   âš ï¸ ä½ç½®å¡«å……å¤±è´¥: {field_key}")
                            except Exception as e:
                                skipped_fields.append(f"{field_key}: {str(e)}")
                                logger.error(f"   âŒ å¡«å……å¼‚å¸¸: {field_key} - {e}")

            # ä¿å­˜æ–‡æ¡£
            doc.save(output_path)
            
            # è¯¦ç»†çš„å¡«å……ç»“æœç»Ÿè®¡
            logger.info(f"âœ… æ–‡æ¡£å·²æˆåŠŸç”Ÿæˆ: {output_path}")
            logger.info(f"ğŸ“Š å…±å¡«å…… {len(filled_fields)} ä¸ªå­—æ®µ:")
            for field in filled_fields:
                logger.info(f"   âœ“ {field}")
            
            if skipped_fields:
                logger.warning(f"âš ï¸ è·³è¿‡ {len(skipped_fields)} ä¸ªå­—æ®µ:")
                for field in skipped_fields:
                    logger.warning(f"   â­ï¸ {field}")
            
            # éªŒè¯æœªå¡«å……çš„æ¨¡æ¿å­—æ®µ
            self._validate_unfilled_fields(template_structure, filled_fields)
            
            return True

        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µ3é”™è¯¯: {e}")
            return False

    def _parse_position_key(self, position_key: str) -> Dict[str, Any]:
        """
        è§£æä½ç½®é”®å€¼ï¼Œæå–è¡Œåˆ—å’Œä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            position_key: å¦‚ "row_3_col_2_ç¼–å·" æˆ– "row_4_left_åŸå½¢åˆ¶_ç°åœºå¤æ ¸æƒ…å†µ"
            
        Returns:
            è§£æåçš„ä½ç½®ä¿¡æ¯å­—å…¸
        """
        try:
            parts = position_key.split('_')
            if len(parts) < 4:
                return None
            
            row = int(parts[1]) - 1  # è½¬æ¢ä¸º0ç´¢å¼•
            
            # å¤„ç†ä¸åŒçš„ä½ç½®æ ¼å¼
            if parts[2] == "col":
                col = int(parts[3]) - 1  # è½¬æ¢ä¸º0ç´¢å¼•
                field_name = '_'.join(parts[4:])
                return {
                    'row': row,
                    'col': col,
                    'field_name': field_name,
                    'fill_type': 'next_cell'
                }
            elif parts[2] == "left":
                context = parts[3]
                field_name = '_'.join(parts[4:])
                return {
                    'row': row,
                    'col': -1,  # è¡¨ç¤ºéœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡æŸ¥æ‰¾
                    'context': context,
                    'field_name': field_name,
                    'fill_type': 'same_cell_with_context'
                }
            
            return None
        except (ValueError, IndexError):
            return None

    def _is_position_match(self, row_idx: int, cell_idx: int, cell_text: str, position_info: Dict[str, Any], row) -> bool:
        """
        åˆ¤æ–­å½“å‰ä½ç½®æ˜¯å¦åŒ¹é…ç›®æ ‡å¡«å……å­—æ®µ
        
        Args:
            row_idx: å½“å‰è¡Œç´¢å¼•
            cell_idx: å½“å‰åˆ—ç´¢å¼•
            cell_text: å½“å‰å•å…ƒæ ¼æ–‡æœ¬
            position_info: ä½ç½®ä¿¡æ¯
            row: å½“å‰è¡Œå¯¹è±¡
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if position_info['fill_type'] == 'next_cell':
            # æ£€æŸ¥æ ‡ç­¾å­—æ®µä½ç½®åŒ¹é…
            return (row_idx == position_info['row'] and 
                    cell_idx == position_info['col'] and 
                    position_info['field_name'] in cell_text)
        
        elif position_info['fill_type'] == 'same_cell_with_context':
            # æ£€æŸ¥ä¸Šä¸‹æ–‡ç›¸å…³çš„å¡«å……
            if row_idx == position_info['row'] and position_info['field_name'] in cell_text:
                # æ£€æŸ¥å·¦ä¾§å•å…ƒæ ¼æ˜¯å¦åŒ…å«ä¸Šä¸‹æ–‡
                if cell_idx > 0:
                    left_cell_text = row.cells[cell_idx-1].text
                    return position_info['context'] in left_cell_text
                    
        return False

    def _fill_cell_by_position(self, cell, row, cell_idx: int, field_value: str, position_info: Dict[str, Any]) -> bool:
        """
        æ ¹æ®ä½ç½®ä¿¡æ¯å¡«å……å•å…ƒæ ¼
        
        Args:
            cell: å½“å‰å•å…ƒæ ¼å¯¹è±¡
            row: å½“å‰è¡Œå¯¹è±¡
            cell_idx: å•å…ƒæ ¼ç´¢å¼•
            field_value: è¦å¡«å……çš„å€¼
            position_info: ä½ç½®ä¿¡æ¯
            
        Returns:
            æ˜¯å¦å¡«å……æˆåŠŸ
        """
        try:
            if position_info['fill_type'] == 'next_cell':
                # å¡«å……ä¸‹ä¸€ä¸ªå•å…ƒæ ¼
                if cell_idx + 1 < len(row.cells):
                    row.cells[cell_idx + 1].text = field_value
                    return True
            
            elif position_info['fill_type'] == 'same_cell_with_context':
                # åœ¨åŒä¸€å•å…ƒæ ¼ä¸­æ·»åŠ å†…å®¹
                cell.add_paragraph(field_value)
                return True
                
        except Exception as e:
            logger.error(f"âŒ å¡«å……å•å…ƒæ ¼æ—¶å‡ºé”™: {e}")
            
        return False

    def _fallback_field_mapping(self, template_structure: Dict[str, str], input_data: Dict[str, str]) -> Dict[str, str]:
        """
        é™çº§å­—æ®µæ˜ å°„ç­–ç•¥ï¼ˆå½“AIæ˜ å°„å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        """
        logger.info("ğŸ”„ æ‰§è¡Œé™çº§å­—æ®µæ˜ å°„ç­–ç•¥...")
        
        mapped_data = {}
        
        # åŸºç¡€æ˜ å°„è§„åˆ™
        mapping_rules = {
            "serial_number": ["ç¼–å·", "number", "id"],
            "project_name": ["é¡¹ç›®åç§°", "name", "title"],  
            "review_date": ["å¤æ ¸æ—¥æœŸ", "date", "check_date"],
            "original_condition_review": ["åŸå½¢åˆ¶", "original_state", "original_form"],
            "damage_assessment_review": ["ç—…å®³å’Œæ®‹æŸ", "damage", "deterioration"],
            "repair_plan_review": ["ä¿®ç¼®åšæ³•", "repair_method", "repair_plan"],
            "project_lead": ["é¡¹ç›®è´Ÿè´£äºº", "project_manager", "manager", "lead"],
            "reviewer": ["å¤æ ¸äººå‘˜", "reviewers", "checker"]
        }
        
        # åå‘æ˜ å°„ï¼šä»è¾“å…¥æ•°æ®å­—æ®µåˆ°æ¨¡æ¿å­—æ®µ
        for template_key in template_structure.keys():
            for input_key, input_value in input_data.items():
                if input_value:  # åªå¤„ç†æœ‰å€¼çš„å­—æ®µ
                    # ç›´æ¥åŒ¹é…
                    if input_key in template_key or any(rule in template_key for rule_list in mapping_rules.values() for rule in rule_list):
                        mapped_data[template_key] = input_value
                        break
                    
                    # è¯­ä¹‰åŒ¹é…
                    for semantic_key, possible_names in mapping_rules.items():
                        if input_key in possible_names or input_key == semantic_key:
                            if any(name in template_key for name in possible_names):
                                mapped_data[template_key] = input_value
                                break
        
        logger.info(f"ğŸ”„ é™çº§æ˜ å°„å®Œæˆï¼Œæ˜ å°„äº† {len(mapped_data)} ä¸ªå­—æ®µ")
        return mapped_data

    def _log_field_statistics(self, template_structure: Dict[str, str]):
        """è®°å½•å­—æ®µç»Ÿè®¡ä¿¡æ¯"""
        field_types = {'basic_info': 0, 'review_situation': 0, 'personnel': 0, 'other': 0}
        
        for key in template_structure.keys():
            if any(info in key for info in ['ç¼–å·', 'é¡¹ç›®åç§°', 'å¤æ ¸æ—¥æœŸ']):
                field_types['basic_info'] += 1
            elif 'ç°åœºå¤æ ¸æƒ…å†µ' in key:
                field_types['review_situation'] += 1
            elif any(person in key for person in ['è´Ÿè´£äºº', 'å¤æ ¸äººå‘˜']):
                field_types['personnel'] += 1
            else:
                field_types['other'] += 1
        
        logger.info(f"ğŸ“Š å­—æ®µç±»å‹ç»Ÿè®¡: {field_types}")

    def _log_data_statistics(self, input_data: Dict[str, str]):
        """è®°å½•è¾“å…¥æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        total_chars = sum(len(str(value)) for value in input_data.values())
        non_empty_fields = sum(1 for value in input_data.values() if value)
        
        logger.info(f"ğŸ“Š è¾“å…¥æ•°æ®ç»Ÿè®¡: æ€»å­—æ®µ {len(input_data)}, éç©ºå­—æ®µ {non_empty_fields}, æ€»å­—ç¬¦æ•° {total_chars}")

    def _log_mapping_statistics(self, template_structure: Dict[str, str], input_data: Dict[str, str], mapped_data: Dict[str, str]):
        """è®°å½•æ˜ å°„ç»Ÿè®¡ä¿¡æ¯"""
        mapped_count = len(mapped_data)
        template_count = len(template_structure)
        input_count = len(input_data)
        
        mapped_with_values = sum(1 for value in mapped_data.values() if value)
        
        logger.info(f"ğŸ“Š æ˜ å°„ç»Ÿè®¡: æ¨¡æ¿å­—æ®µ {template_count}, è¾“å…¥å­—æ®µ {input_count}, æ˜ å°„å­—æ®µ {mapped_count}, æœ‰å€¼å­—æ®µ {mapped_with_values}")
        
        # æ£€æŸ¥æœªæ˜ å°„çš„æ¨¡æ¿å­—æ®µ
        unmapped_template = [key for key in template_structure.keys() if key not in mapped_data or not mapped_data[key]]
        if unmapped_template:
            logger.warning(f"âš ï¸ æœªæ˜ å°„çš„æ¨¡æ¿å­—æ®µ ({len(unmapped_template)}): {unmapped_template}")
        
        # æ£€æŸ¥æœªä½¿ç”¨çš„è¾“å…¥å­—æ®µ
        used_input_values = set(mapped_data.values())
        unused_input = [key for key, value in input_data.items() if value and value not in used_input_values]
        if unused_input:
            logger.warning(f"âš ï¸ æœªä½¿ç”¨çš„è¾“å…¥å­—æ®µ ({len(unused_input)}): {unused_input}")

    def _validate_unfilled_fields(self, template_structure: Dict[str, str], filled_fields: List[str]):
        """éªŒè¯æœªå¡«å……çš„å­—æ®µ"""
        filled_field_keys = [field.split(' -> ')[0] for field in filled_fields]
        unfilled_keys = [key for key in template_structure.keys() if key not in filled_field_keys]
        
        if unfilled_keys:
            logger.warning(f"âš ï¸ æ¨¡æ¿ä¸­æœ‰ {len(unfilled_keys)} ä¸ªå­—æ®µæœªè¢«å¡«å……:")
            for key in unfilled_keys:
                logger.warning(f"   ğŸ” æœªå¡«å……: {key}")

    def run_enhanced_workflow(self, doc_template_path: str, json_input_path: str, output_path: str):
        """
        è¿è¡Œå¢å¼ºç‰ˆçš„å®Œæ•´å·¥ä½œæµç¨‹
        """
        logger.info("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆAIæ–‡æ¡£ç”Ÿæˆæµç¨‹")
        logger.info("=" * 60)
        
        start_time = datetime.now()
        
        try:
            # é˜¶æ®µ0ï¼šDOCè½¬DOCXè½¬æ¢
            docx_template_path = self.convert_doc_to_docx(doc_template_path)
            logger.info("=" * 30)
            
            # é˜¶æ®µ1ï¼šä½ç½®æ„ŸçŸ¥çš„æ¨¡æ¿åˆ†æ
            template_structure = self.stage1_analyze_template_with_position(docx_template_path)
            logger.info("=" * 30)
            
            # é˜¶æ®µ2ï¼šåŠ è½½JSONæ•°æ®
            input_data = self.stage2_load_json_data(json_input_path)
            logger.info("=" * 30)
            
            # é˜¶æ®µ2.5ï¼šå¢å¼ºç‰ˆAIå­—æ®µæ˜ å°„
            mapped_data = self.stage2_5_enhanced_ai_field_mapping(template_structure, input_data)
            logger.info("=" * 30)
            
            # é˜¶æ®µ3ï¼šä½ç½®æ„ŸçŸ¥çš„æ¨¡æ¿å¡«å……
            success = self.stage3_position_aware_template_filling(docx_template_path, output_path, mapped_data, template_structure)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            logger.info("=" * 60)
            if success:
                logger.info("ğŸ‰ å¢å¼ºç‰ˆAIæ–‡æ¡£ç”Ÿæˆæµç¨‹å®Œæˆ!")
                logger.info(f"â±ï¸ æ€»ç”¨æ—¶: {duration:.2f} ç§’")
                logger.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_path}")
                logger.info(f"ğŸ”„ ä¸­é—´è½¬æ¢æ–‡ä»¶: {docx_template_path}")
            else:
                logger.error("âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ å¢å¼ºç‰ˆå·¥ä½œæµç¨‹å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¢å¼ºç‰ˆAIæ–‡æ¡£ç”Ÿæˆå™¨ - ä¸»ç¨‹åº")
    print("=" * 50)
    
    # é…ç½®
    API_KEY = "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"
    
    # æ–‡ä»¶è·¯å¾„
    doc_template_path = "template_test.doc"
    json_input_path = "sample_input.json"
    output_path = f"å¢å¼ºç‰ˆAIç”Ÿæˆæ–‡æ¡£_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(doc_template_path):
        logger.error(f"âŒ DOCæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {doc_template_path}")
        return
    
    if not os.path.exists(json_input_path):
        logger.error(f"âŒ JSONè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {json_input_path}")
        return
    
    # åˆå§‹åŒ–å¢å¼ºç‰ˆç”Ÿæˆå™¨
    try:
        generator = EnhancedAIDocGenerator(API_KEY)
    except Exception as e:
        logger.error(f"âŒ å¢å¼ºç‰ˆç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # è¿è¡Œå¢å¼ºç‰ˆå®Œæ•´æµç¨‹
    success = generator.run_enhanced_workflow(
        doc_template_path=doc_template_path,
        json_input_path=json_input_path,
        output_path=output_path
    )
    
    if success:
        print(f"\nâœ… æˆåŠŸï¼ç”Ÿæˆçš„æ–‡æ¡£: {output_path}")
    else:
        print("\nâŒ å¤±è´¥ï¼è¯·æ£€æŸ¥æ—¥å¿—ä¿¡æ¯")


if __name__ == "__main__":
    main() 